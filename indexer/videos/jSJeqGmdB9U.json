{
  "id": "jSJeqGmdB9U",
  "title": "This Project Got Me Promoted to Cloud Engineer",
  "transcript": "so it's just for context everyone like\nI'm you know I have the baby bit uh logo\nup here because you know put yourself in\nmy shoes really want you to live this\nexperience with me you know I'm young\ninto my career I'm not really great\nconfident in my skill set but you know\nI'm excited and I've got my manager that\napproaches me and says like when we have\nthis process that we want you to build a\nsolution end to end he didn't say you\nhave to use a specific service you got\nto do a specific way I was kind of just\ntasks with this right so you know here\nyeah uh very grateful for the\nopportunity excited nervous in things\nright so this is the context of of this\nproject right so let's talk a little bit\nabout what the actual problem was I\nneeded to be automated so I had two\ncolleagues uh that were spending their\nmornings manually submitting files to a\nwebsite and I've highlighted here words\nthat I think are are\nsort of key to this problem here so they\nwere spending their mornings manually\nsubmitting files to a website and this\ncombined three hours between both of\nthem every single day and six days a\nweek because this is a process that\nneeded to be done Monday through\nSaturday this was in the energy industry\nI don't know if anyone has any\nexperience working with the energy\nindustry but they have all sorts of\nrules limitations very old processes as\nwell things that have to be submitted\nit's weird because there's some stuff\nthat has to be submitted like exactly 9\n59 in the morning and if it's one minute\nafter it's considered the next day a\nbunch of different things so if anyone\nhas any uh experience in the industry in\nthe energy industry let me know in the\nchat but anyway so the total was 18\nhours of manual work a week right and\nI've actually got here a representation\nof my frustrated colleagues uh that you\nknow they just wanted to spend their\ntime this 18 hours of time that they\nhave per week doing things where they're\nactually working on the skill set that\nis specific to their role and not just\ndoing something that you could automate\nsomething that was manual something that\nwas really sort of boring in one right\nwanted to spend their time more\nmindfully and I think this is also\nimportant when we think about automation\nbecause when we when we think automation\nwe think people lose their job but if\nyou work at the right place you've got\nthe right team around you you've got the\nright management and Leadership they can\nturn that time that was saved into more\nmindful work for your team which is what\nended up happening in this process which\nis great\num but anyway now let's talk a little\nbit about the approach again still you\nknow young Gwen uh early in career Still\nStill baby bit here but I through\nconversation I sat down with the team\nwho were actually doing this process and\nI'd figure out okay there's some key\nfacts here that makes me think that I\nshould use a serverless approach here so\nanyway first of all again this is our\nour team here sitting in a co-working\nenvironment but anyway first of all the\nfirst the whole process I knew for each\nfile to be submitted uh would take a few\nminutes so it wasn't a long run it\nwasn't something that needed to run for\ndays or hours or anything like that so\nfrom them getting the file to submitting\nit to this website it was a couple of\nminutes so that's a key fact there\nthen I also knew that these files could\nbe processed independently so none of\nthese files appended it depended on each\nother it was one file uploads submit\ndone move on to the next file which is\nimportant I think there was at that\npoint when I first created the solution\nfrom 50 to 60 files but the goal was to\nhave more and more files depending on\nmore clients coming in and whatnot but\nagain order didn't matter they didn't\nhave to be done together they just had\nto be processed at some point important\nhere too\nuh another key factor that I that I\nfound out was that each file had a\nusername and a password that rotates\neach 90 days so in order for whatever\nprocess that I was going to create it\nneeded to be able to securely access\nthese credentials and these credentials\nalso needed to be in a place that we\ncould in a streamlined way update them\nbecause they need to be rotated every 90\ndays right so that's also important here\nthen I knew that the files that actually\nget uploaded were generated by an\nexisting system and then these analysts\nmy colleagues were downloading the files\nfrom the existing system manually but I\nspoke to the lead engineer on that\nproject and then that he essentially\ntold me like yeah we're just sort of\ngenerating them and not putting them\nanywhere but if you gave me a place\nwhere you wanted them to go get saved I\ncould do that for you so I was like okay\ncool key fact right there too so I know\nI could get the files to get once they\nwere generated to go somewhere where I\nneeded them to go\nvery very important part is the website\nwhere we were actually uploading these\nfiles to had an API so if you are a\ndeveloper you do any engineering work\nyou know apis are important when it\ncomes to automating and having systems\ncommunicate with each other if it had an\nAPI we were probably looking at using\nlike um what's that technology that you\ncan uh or that service that you can use\nto automate like clicks in a website\nthere's I can't remember oh yeah there\nis something it's basically you can\ncrawl\nyeah something like that but it would\nhave made this process a lot more\ndifficult but the way that I found out\nthat this website had an API and again\nwe're thinking energy industry was kind\nof frustrating because I had to email\ntheir support team wait like I don't\nknow a week to get a response back and\nthey emailed me back a 60 page PDF that\nwas to be fair it had everything but I\nhad to literally go through the entire\nthing to get you know okay you need to\nhave this type of of information in the\nheaders you need to like this type of\ninformation here's the URL and whatnot\nand things like that responses to expect\nand all that kind of stuff so\nkey factor of the website had an API\nfinally I also knew that it was\nimportant that the website respond like\nthe website response itself was\nimportant because uh and it'd be if it\nwasn't a success the file needs to be\nprocessed again but it was important\nthat every single file get processed and\neven if it was successful or not\nsuccessful that response was going to be\nyou need to save somewhere because my\ncolleagues were going to need to be able\nto see okay oh just to verify the manual\nverification there everything looks\ngreen perfect okay so then\nso let's talk about this let's in steps\nso I have this key the the key facts and\nI'm like okay so now I understand the\nactual manual process and when you're\nautomating something it's very important\nthat you understand every single bit so\nit's like think about like when you're\ntrying to change a light bulb it's not\nlike oh just change the light bulb like\nno it's like step one do you have\num is it the light bulb the actual issue\nlike turn the light on is the light\nworking in other places sorry you've\nfigured out the light bulb do you have\nan actual spare light bulb you don't\nwant to go up to go change your light\nbulb and turns out you don't have to\nspare the light bulb then you gotta go\nto the store right so when you think of\nthem automating a manual process it's\nall about every single little step and\neverything that could go go right and\nwrong in this expect a new one all right\nso let's talk about the steps here so\nfirst of all uh we know that we have to\nget the files automatically go somewhere\nonce they are made available by that\nexisting system and we know that for\nthat requires the the change in that\nexisting system to be done by the team\nthat handles that system uh awesome okay\nSecond Step here is that I know that as\nsoon as a file is in that place we need\nto process it\nthe actual process the steps and process\nis obtaining the file then we need to\nobtain the credential\nthen we need to parse the XML because\nthese files are XML data and that API\nwas expecting XML then we needed to\nsubmit the XML with the correct\ncredential to the API if the API\nreturned a successful response we needed\nto Archive the file because it's been\nprocessed we don't need it anymore and\nwhen you have like a hot hot storage\nversus archive storage there's a\nsignificant price reduction in storage\nthat you use just for archiving so the\nmore we can save money the better\nand if the API didn't return a success\nwe don't move the file we have to leave\nit in the same place that it is so it\ncan get processed again fantastic then\nwe need to regardless of what the\nresponse is save the response somewhere\nsave the API response somewhere and also\nI mentioned that we needed to be able to\nupdate credentials and we also needed to\nbe able to see\num the actual responses I like this\ncommon XML horror yes yeah I'm Marvel\nfan of Json myself but hey XML exists a\nlot and it's still very used in many\nmany places but yes it was\nit would have been so much easier to\nwork with Json but yeah we have XML\nthere so anyway additional tools uh we\nneed to create a credential updater yes\nof course because we need to interact\nwith this service that was going to\nshare there's always keep the\ncredentials and we needed to build some\nsort of static website that my\ncolleagues could just visit and they go\nto the website and to see all the\nresults and then easily see it's green\nand green green if there's something red\nthen oh they have an idea of what needs\nto get processed again maybe they kick\noff the automation process or whatever\nonce more okay so anyway now we have all\nthe steps and now we talk about the plan\nhere again still kind of like early on\nnot as confident but yeah we're going\ninto it right so we got the plan now\nthings are about to get I'm warning you\nall things are about to get chaotic but\nthat's sort of how it is when you're\nsort of like you know you know putting\nthe process together kind of figuring\nthings out you're kind of doing a brain\ndump there's kind of things can get a\nlittle chaotic until like you know they\nsmooth it now and you actually figure\nstuff out right but anyway so again\nlet's let's map these steps into Azure\nservices so we need the files to go\nsomewhere well\nperfect solution for that would be blob\nstorage and like I mentioned blob\nstorage is essentially a serverless\nstorage service with Azure okay so I\ncould give the blob storage\num the proper like SAS or token or\nhowever it is that you want to your\nservice to connect to\num I know it was like I think it was\nlike a net application so they were able\nto just get like okay these files are\nmanually uh with these files are\ngenerated we'll send them straight off\nto a blob container there in Azure\nstorage\nthen I know that we need to process each\nfile as they come in Azure functions is\na perfect service for that Azure\nfunctions has a bunch of triggers and\nbindings triggers are ways that your\nyour event driven code which is what\nfunctions are can execute can run and\nthen blob trigger would mean that okay\nyour function is expecting some sort of\nchange in some sort of blob container\nwhich is the change in this case would\nbe oh yeah a new file is available let's\ndo something with it so we're going to\nuse functions to obtain the file\nright and then the next step here is to\nobtain the credential now I mentioned we\nhave to have a safe place safe secure uh\ntop-notch security uh where we can\nmaintain our credential but we also need\nit to be somewhere that we can update in\nsomewhat of a streamlined way for that\nwe have key Vault keyboard hottest sdks\nand apis that you can use to securely\ninteract and update with them but also\nyou can use an access policy within\nAzure to have your Azure functions and\nkey Vault to talk to each other and when\nwe're in the solution diagram we'll see\nthat there's a back and forth here but\nfor right now this is let's think of\nlike the Soto code like before you\nactually code you have SoDo code right\nso this is like Soto diagram\num with Cloud infrastructure and whatnot\nokay so then parse XML that was another\njob before the function itself and we've\ngot it here pointing to the function now\nremember I told everyone there is one\nbig change I would make in my updated\nsolution if I were to rebuild this thing\nin 2022. I'm going to tell you in this\nslide you can probably get a feel for\nwhat it was but\npay attention Okay so anyway then we've\ngot to submit the XML with credential to\nthe API and again regardless of the\nresponse we need to save that too and\nthen we need to\nthe actual submission of that of that\ndata will be done from that function as\nwell\nnext we've got to save the API response\nwe need to actually grab that data and\nput it somewhere table storage is\nprobably like the cheapest and more\nstraightforward way and you can have an\noutput binding on the Azure function to\nsave to table storage so perfect like\ntable storage a couple of cents a month\nwe'll talk more about the actual\nfinances of the solution later on a\ncouple cents a month we don't need\nCosmos DB we don't need an Azure SQL\ndatabase for this like no it's a simple\ntable storage would do it for us\nfinally we need to create the additional\ntools which would be a credential\nupdater remember we're going to have\ncredentials in key Vault so we need to\nbe able to rotate those every 90 days or\nso so I built this we're going to use a\npython uh well I used I guess a python\nSDK to interact with key Vault and then\nwe needed a static site to view the\nresults remember that\nBlazer uh I don't know if anyone has\nexperience with laser I'm a big fan\nBlazer allows you to use.net\nTechnologies to develop full stack\napplications you have Blazer webassembly\nwhich runs off webassembly technology\nand you're using.net for just static\nwebsites you have Blazer server side\nthat has a server and a front-end\num very cool technology there but anyway\nyes this is essentially a stepson Azure\nright so again everything's a little\nchaotic but you might be able to get a\nfeel for what changes I would have done\nbut anyway we've got essentially all the\nservices that we're going to work with\nhere okay so now at this point in my in\nmy in my I guess\nexperience or my time with this project\nI've got I've sat down with my\ncolleagues I I got all my key facts I I\nI've approached a thing I've planned it\nout and I'm feeling more confident so\nnow we've graduated to a bit with a\nlaptop and ready to work in Azure what\nnot so we're going to dive into the\nsolution right so for the solution\nitself that first step is let's save the\nfiles and remember I mentioned that this\nis some sort of internal application\nthat another engineer has built\nso we need to get these files these\ngenerated files get saved to something\nand I added a note there that says it\nmight be a little too small but what it\nsays is that these files are saved using\na naming convention and this is\nimportant for a Next Step that we have\nuh coming up here but yeah I'm a\nconvention we're going to use blob\nstorage we're going to we have here\nprocessing blob storage which are files\nthat were manually downloaded are now\ngoing to go straight into blob storage\nand blob storage each file there is\ngoing to trigger an Azure function right\nquick question so yes the the file that\nthe internal application generates\ndo engineers put them manually in the\nblob storage\nno they okay it uses\num probably like uh blob storage API or\nprobably SDK uh like done at SDK just\nget the files to go straight into things\nso that was automated as well none of\nthe process from it was manual unless it\nwas manual verification or maybe like\nresubmission needed to be done again\num but that was a good question there\nokay so yeah we know that as soon as a\nfile hits a blob storage each in each\nfile each it's not just like a group of\neach file so we're talking about 50 60\nfiles is going to trigger this process\nXML file here too now remember that I\nsaid there was a naming convention so\nthe files were being saved like for\nexample uh I don't know company name\nDash something dot XML that naming\nconvention was important because that is\nwhat the function the function would\ngrab the name of the file and then go to\nKevon it's like okay keyboard return me\nthe the credential that matches this\nnaming convention so you see there's a\ntwo-way Arrow here because key Vault\nwould return that credential to the\nAzure function now\nthe reason that the credential sort of\nlike the grabbing the credential is the\nfirst step here is because there is no\npoint in processing the actual XML or\nthe file if I can't find the proper\ncredential right because you're not\ngoing to be able to submit it to the API\nso that's the first step here so\nconsidering everything works out we're\nlike okay the key vault is returning now\nthe credential back into the Azure\nfunction and then the function has\neverything it needs to parse the XML and\nsend it off to the submission website\nAPI we're just calling it submission\nwebsite that's not the actual official\nname so the function sends off that XML\ndata with a credential and sends it off\nto the API and the API will return some\nsort of response again rather it's like\nsuccessful or not successful response we\nneed to save the response somewhere next\nthat same function did you have a\nquestion\nso the credentials were file specific or\nwere they required as headers for the\nsubmission website\nuh yeah they were required as headers so\nwe would parse the the key Vault has a\nkey value pair and we would grab those\nand send them off in the call and then\nwe would send the XML data with a call\nas well makes sense yeah um like the\npayload I guess um so then response\nagain we're using table storage to keep\nthe responses uh Table stores is a very\nvery simple\nlike you think you think of a table in a\ndatabase very very simple service\num compared to something like Cosmo ZB\nor Azure SQL and whatnot so the function\nwill save the API response to the table\nand then of course we talked about\narchiving files as well the function\nwould then archive the file if it was a\nsuccess so this is the diagram according\nto if it was a successful submission of\ncourse now\npay attention to this we're gonna this\nand I have like sort of this\nrectangle here that just kind of tells\nyou what is built in Azure and what is\nsort of on-prem so remember that\ninternal service was deployed on a\nvirtual machine that lived on-prem and\nthen we had everything that's inside the\nblue which is indicating a resource\nGroup living inside of azure right so\npaid digit here to sort of what you\nthink you would change or what you think\nneeds to be changed and this solution at\n50 60 files runs fine but if you throw\n1000 files at this if you throw several\nthousand which obviously this this this\ncompany wanted to obtain you more and\nmore clients and as more clients would\nonboard to their catalog they would have\nmore and more files right so their goal\nwas to be able to to process these files\num you know you start to hear\nperformance issues with this current\nsolution if you get into the you know\nseveral thousand probably several\nthousands of files but anyway if anyone\nhas an idea in the chat let me know but\nanyway now it's not just the solution\nitself I tend I I mentioned that I had\nalso built a couple of helper tools so\nthe first thing was building essentially\na CLI that would interact with a key\nVault using python so you know if you\nuse the CLI before it was essentially\nsomething that said uh username like\nupdate I don't know I can't remember\nwhat my prefix was but it was like\nupdate key ball uh you would provide the\nusername and tell you okay which what's\nthe new password you want to do and then\nit would go into key Vault and update\nthat\num\ncorrectly\nuh worship you want to take a guess let\nme let me let me take a guess before\nbefore I show you the updated one too\nokay cool cool cool cool so that was the\nfirst the the this was a great this is a\ngreat experience using python using sdks\nwith Azure it was a very straightforward\nthing but it was my first time using\npython in a professional setting so it\nwas a lot of fun\num and it was something like pretty easy\nto run to uh and then the next thing was\na static results website which I was\nusing Blazer web assembly on the front\nend and every time you would hit and it\nwas deployed on app service I believe or\nmaybe it was even deployed on blob\nstorage\num just like a static site so every time\nyou would hit the website URL it would\ngo call an HTT to be triggered Azure\nfunction that would get a a\nthe results of all the table and parse\nit to Json and return Json back to the\nsite and then the site was a very simple\nstatic site it would say a file name\nsuccess file name or or whatever the\nresponse was and the time that it was\nsubmitted uh and and whatnot I like\nsomeone says Azure Q storage okay you're\ngetting there that's a good guess I like\nthat guess there it's a good guess there\nso anyway\num now I want to talk a little bit just\nabout making my case for promotion\nbecause\nyou know we work we build we upskill\nbecause essentially we want career\nadvancement we want more money like\nthere's nothing wrong in saying these\nkinds of things but earlier even before\nI was in this role someone gave me some\nof the best advice that I've taken in my\nentire career which is like the people\nwho promote you don't necessarily care\nabout\nthe tech itself because the tech that\nyou need to be able to work with will\nchange like I don't know weekly monthly\nyearly what not they care about how\nefficient you can be and how you can\nsave them time and how you can save them\nmoney so every time that I would try to\napproach a a promotion I would make sure\nI can talk in ways that like oh what was\nthe actual outcome of my project it's\nnot like oh I implemented containers or\nI implemented serverless or I automated\nsomething it's like what was the actual\noutcome what was the actual impact oh\nand we see Mike Mike drop bit here you\nsee this is bit dropping a microphone\nit's pretty good yeah I was actually I\nwas I was\nvery proud after this project because I\nhad been talking to my colleagues\nthey're like you know we have so much\ntime left like this is all streamlined\nthat we know that this process is\nworking all these kinds of things I was\nvery confident but there's a one line\nhere if I had to summarize this project\nwas my solution frees up 18 hours of\nmanual work a week and runs for under\none dollar a month now I don't really\nknow the salary of their it was like but\nif we you know estimate that they were\nmaking I don't know fifty dollars an\nhour you know it averages about two\nthousand dollars a month you're\ncomparing a thousand dollars a month to\na solution that runs under a dollar to\nbe exact the solution was running for 30\ncents a a month but I just put a dollar\nbecause a little bit more catchier here\nbut\num yeah for 30 cents and the functions\nexecution was free because you have a\ngrant I think per subscription with\nfunctions I think it's monthly of a\nmillion executions so the compute is\ncompletely free this was just storage\nand if I was probably a little bit more\nclever with the storage I'd probably say\nbut you know 30 cents compared to a\nthousand dollars a month massive\ndifference and after this I was promoted\nand then I spent a whole another year as\na junior college Union at this at this\nat this company and got a lot more\nHands-On Azure and years later I'm here\nworking at Microsoft's but anyway let's\ndive into the fun part I wanted to see\nsomeone said either that or service bus\nso Richard did you want to take a guess\nyeah I was going to say some kind of\ncooling service okay yes queuing queuing\nmessaging so when we think of um\ndistributed systems which cloud is all\nabout like the more distributed that you\ncan make it the more Advantage you can\ntake it of different services in in the\ncloud and whatnot\num you're gonna get the best bang for\nyour buck and one so yes\nwe are talking about having a messaging\nservice and I would add another function\nbecause that that initial function was\ndoing a little bit too much so I would\nnow abstract away the the archiving so\nthe actual moving of the files and the\nsaving of the response to table source\nto another function and that way that\ninitial function can scale to process as\nmany files as it needs to without\nhitting like any performance issues so\nin this case I have event grids\num it I think Azure has event grids\nyou've got\num I can't remember we have like four\ndifferent messaging services I know\nsomeone mentioned service bus uh Q\nstorage as well but it you know it\nreally kind of depends on like what\nyou're doing like aiming for cues versus\nevents and messages versus events and\nwhatnot events tend to work a lot better\nwith serverless and whatnot so I would\nhave\num\nevent grid here and then you can trigger\nan Azure function with event grid so\nwhen there's a new event and you can\nsend like information with it so file\nname and then response and then that\nfunction would archive and then save\nresponse I could probably do\nanother function that so it was just\nlike one archives and one does the\nsaving the response to table storage but\nthat was probably a little bit too\nOverkill but this would be the updated\nversion of my solution uh and if I\nactually implemented it in 2022",
  "key_phrases": [
    "cool key fact",
    "one file uploads",
    "one minute",
    "one right",
    "skill set",
    "specific service",
    "old processes",
    "manual work",
    "mindful work",
    "young Gwen",
    "working environment",
    "existing system",
    "lead engineer",
    "right management",
    "key factor",
    "energy industry",
    "next file",
    "baby bit",
    "specific way",
    "actual problem",
    "serverless approach",
    "important part",
    "three hours",
    "different things",
    "manual something",
    "right place",
    "50 to 60 files",
    "right team",
    "18 hours",
    "context",
    "everyone",
    "logo",
    "shoes",
    "experience",
    "career",
    "manager",
    "solution",
    "tasks",
    "opportunity",
    "project",
    "two",
    "colleagues",
    "mornings",
    "website",
    "words",
    "sort",
    "Monday",
    "limitations",
    "stuff",
    "bunch",
    "uh",
    "chat",
    "total",
    "representation",
    "frustrated",
    "time",
    "week",
    "role",
    "automation",
    "people",
    "job",
    "Leadership",
    "conversation",
    "facts",
    "minutes",
    "long",
    "days",
    "couple",
    "none",
    "point",
    "goal",
    "clients",
    "order",
    "username",
    "password",
    "access",
    "credentials",
    "streamlined",
    "analysts",
    "API",
    "developer",
    "actual spare light bulb",
    "significant price reduction",
    "hot hot storage",
    "single little step",
    "common XML horror",
    "actual manual process",
    "actual issue",
    "manual verification",
    "actual process",
    "actual responses",
    "engineering work",
    "energy industry",
    "60 page PDF",
    "entire thing",
    "other places",
    "new one",
    "Second Step",
    "archive storage",
    "Marvel fan",
    "additional tools",
    "automation process",
    "key factor",
    "single file",
    "key facts",
    "existing system",
    "correct credential",
    "credential updater",
    "support team",
    "same place",
    "many places",
    "XML data",
    "successful response",
    "static website",
    "website response",
    "API response",
    "apis",
    "systems",
    "um",
    "technology",
    "service",
    "clicks",
    "something",
    "crawl",
    "everything",
    "type",
    "information",
    "headers",
    "URL",
    "things",
    "kind",
    "stuff",
    "colleagues",
    "steps",
    "store",
    "files",
    "change",
    "money",
    "credentials",
    "Json",
    "lot",
    "course",
    "share",
    "sort",
    "results",
    "idea",
    "plan",
    "key Vault keyboard hottest sdks",
    "full stack applications",
    "event driven code",
    "big fan Blazer",
    "Azure SQL database",
    "simple table storage",
    "Blazer server side",
    "serverless storage service",
    "key facts",
    "Blazer webassembly",
    "perfect service",
    "next step",
    "safe place",
    "top-notch security",
    "access policy",
    "Soto diagram",
    "Cloud infrastructure",
    "Cosmos DB",
    "additional tools",
    "static site",
    "webassembly technology",
    "static websites",
    "cool technology",
    "first step",
    "internal application",
    "naming convention",
    "blob storage",
    "blob container",
    "blob trigger",
    "big change",
    "Soto code",
    "Azure storage",
    "net application",
    "bindings triggers",
    "actual submission",
    "straightforward way",
    "python SDK",
    "perfect solution",
    "new file",
    "solution diagram",
    "Azure functions",
    "credential updater",
    "Azure services",
    "API response",
    "couple cents",
    "brain",
    "dump",
    "kind",
    "things",
    "stuff",
    "steps",
    "files",
    "SAS",
    "token",
    "bunch",
    "ways",
    "sort",
    "case",
    "something",
    "streamlined",
    "apis",
    "XML",
    "job",
    "everyone",
    "slide",
    "feel",
    "attention",
    "cheapest",
    "output",
    "finances",
    "credentials",
    "results",
    "experience",
    "laser",
    "Technologies",
    "front-end",
    "everything",
    "changes",
    "point",
    "time",
    "project",
    "colleagues",
    "bit",
    "laptop",
    "engineer",
    "note",
    "key value pair",
    "actual official name",
    "processing blob storage",
    "Azure function right",
    "blob storage API",
    "submission website API",
    "process XML file",
    "actual XML",
    "internal application",
    "manual verification",
    "two-way Arrow",
    "first step",
    "simple service",
    "Cosmo ZB",
    "successful submission",
    "internal service",
    "virtual machine",
    "performance issues",
    "helper tools",
    "first thing",
    "key ball",
    "new password",
    "great experience",
    "Azure SQL",
    "key Vault",
    "table storage",
    "quick question",
    "good question",
    "naming convention",
    "company name",
    "same function",
    "Table stores",
    "resource Group",
    "current solution",
    "API response",
    "XML data",
    "successful response",
    "credential sort",
    "files",
    "engineers",
    "SDK",
    "things",
    "none",
    "resubmission",
    "example",
    "something",
    "Kevon",
    "keyboard",
    "reason",
    "point",
    "proper",
    "everything",
    "credentials",
    "headers",
    "call",
    "sense",
    "payload",
    "responses",
    "database",
    "course",
    "diagram",
    "attention",
    "rectangle",
    "prem",
    "digit",
    "several",
    "clients",
    "catalog",
    "goal",
    "thousands",
    "idea",
    "chat",
    "couple",
    "python",
    "username",
    "update",
    "prefix",
    "guess",
    "Blazer web assembly",
    "junior college Union",
    "success file name",
    "different messaging services",
    "static results website",
    "Azure Q storage",
    "different services",
    "website URL",
    "straightforward thing",
    "professional setting",
    "next thing",
    "app service",
    "career advancement",
    "entire career",
    "weekly monthly",
    "actual outcome",
    "actual impact",
    "Mike Mike",
    "one line",
    "manual work",
    "fifty dollars",
    "thousand dollars",
    "million executions",
    "service bus",
    "cooling service",
    "distributed systems",
    "actual moving",
    "performance issues",
    "event grids",
    "new event",
    "static site",
    "good guess",
    "blob storage",
    "initial function",
    "best advice",
    "functions execution",
    "fun part",
    "table source",
    "many files",
    "Azure function",
    "one dollar",
    "first time",
    "python",
    "lot",
    "something",
    "front",
    "end",
    "HTT",
    "parse",
    "Json",
    "simple",
    "response",
    "someone",
    "case",
    "promotion",
    "money",
    "kinds",
    "things",
    "role",
    "people",
    "will",
    "ways",
    "project",
    "containers",
    "serverless",
    "microphone",
    "colleagues",
    "process",
    "solution",
    "18 hours",
    "salary",
    "cents",
    "grant",
    "subscription",
    "compute",
    "difference",
    "year",
    "company",
    "Microsoft",
    "Richard",
    "um",
    "cloud",
    "Advantage",
    "archiving",
    "saving",
    "cues",
    "events",
    "messages",
    "information",
    "ld archive",
    "one archives",
    "table storage",
    "response",
    "function",
    "Overkill",
    "version",
    "solution"
  ]
}